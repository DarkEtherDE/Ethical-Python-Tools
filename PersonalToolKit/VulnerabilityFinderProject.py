import argparse
from socket import *
import pyfiglet
import textwrap
import threading
import time
from queue import Queue
import requests
from bs4 import BeautifulSoup
import os
import socks
import sys
from lxml import etree
from io import BytesIO
from urllib.parse import urljoin
import random
#Goal Modules to incorporate

#SQL injection attacks: You could add modules to perform SQL injection attacks by crafting malicious SQL statements to exploit vulnerabilities in the application's database.

#Cross-Site Scripting (XSS) attacks: You could add modules to inject malicious scripts into the application's web pages and steal user credentials or perform other malicious actions.

#File inclusion attacks: You could add modules to exploit vulnerabilities in the application's file inclusion mechanisms to read or execute arbitrary files on the server.

#Remote code execution: You could add modules to exploit vulnerabilities in the application's server-side code to execute arbitrary code on the server.

#Authentication bypass: You could add modules to bypass authentication mechanisms by exploiting vulnerabilities such as session fixation, password reset attacks, or brute-force attacks.

#Directory traversal attacks: You could add modules to exploit vulnerabilities in the application's directory traversal mechanisms to access files and directories outside the application's web root directory.

#XML External Entity (XXE) attacks: You could add modules to exploit vulnerabilities in the application's XML parsing mechanisms to read arbitrary files on the server or execute code.

#Server-side request forgery (SSRF) attacks: You could add modules to exploit vulnerabilities in the application's server-side request processing to make unauthorized requests to other internal or external systems.

#Extra for appearance
ascii_banner = pyfiglet.figlet_format("Vulnerability Finder 101")
print(ascii_banner)

AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
EXTENSIONS = ['.php', '.bak', '.orig', '.inc']
THREADS = 50
WORDLIST = "all.txt"
s = requests.Session()
s.headers["User-Agent"] = AGENT
class PortScanner:
    def connect(targetHost, targetPort):
        socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS5, "localhost", 9150)  # Configure SOCKS proxy (Tor)
        socket.socket = socks.socksocket  # Patch the socket module to use the SOCKS proxy
        
        s = requests.Session()
        s.headers["User-Agent"] = AGENT
        
        with open('Hostports.txt', 'a') as file:
            try:
                response = s.get('http://' + targetHost + ':' + str(targetPort))
                if response.status_code == 200:
                    banner = response.headers.get('Server', 'Unknown banner')
                    result = '{}: {}'.format(targetPort, banner)
                    file.write(result + '\n')
                    print("Banner:", banner)
                else:
                    print("[-] Unable to grab any information. Response status code:", response.status_code)
            except ConnectionError as e:
                print('[-] Unable to grab any information:', e)
            finally:
                return targetHost, targetPort

    def grab(conn, port, file):
        try:
            conn.settimeout(2)
            conn.send(b'GET / HTTP/1.1\r\nHost: example.com\r\n\r\n')
            ret = conn.recv(4096)  # Adjust buffer size if needed

            print('[+] Connected to Host:\n --Attempting Banner Grab: {}'.format(ret))
            ret = ret.decode('utf-8', errors='ignore')  # Use appropriate decoding and handle errors

            if ret.startswith("SSH-2.0"):
                banner_start = len("SSH-2.0")
                banner_end = ret.find("\r\n", banner_start)
                banner = ret[banner_start:banner_end].strip()
            elif ret.startswith("220"):
                banner_start = len("220")
                banner_end = ret.find(" ", banner_start)
                banner = ret[banner_start:banner_end].strip()
            elif ret.startswith("HTTP/1"):
                banner_start = ret.find("Server: ") + len("Server: ")
                banner_end = ret.find("\r\n", banner_start)
                banner = ret[banner_start:banner_end].strip()
            else:
                banner = "Unknown banner"
                ret = '{}\n'.format(str(ret))
                print(ret, ': Test')
                file.write(ret)
                return

            print("Banner:", banner)
            result = '{}: {}'.format(port, banner)
            file.write(result + '\n')

        except Exception as e:
            print('[-] Unable to grab any information: {}'.format(e))
            return

    def grabHttp(conn,port):
        try: 
            conn.send(b'GET HTTP/1.1 \r\n') 
            ret = conn.recv(1024) 
            print ('[+] {}\n'.format(ret)) 
            file = open('Hostports.txt', 'a')
            ret = '{}: {}\n'.format(port, str(ret))
            file.write(ret)
            return
        except Exception as e: 
            print ('[-] Unable to grab any information: {}'.format(e)) 
            return
        
    def main(target):
        targetHosts=None
        targetPorts=None
        targetHosts = target
        targetPorts = input("Target Ports (in range of a,b): ")
        targetHosts = str(target).split(',') 
        targetPorts = int(targetPorts) 
        
        for targetHost in targetHosts:
            for targetPort in range(targetPorts):
                targetPort = targetPort+1
                PortScanner.connect(targetHost, int(targetPort))
                print('')
            
class dataGatherer():

    def get_words(resume=None):#feeds words, looks for a pause, if pause found, resume from list
        def extend_words(word):
            if "." in word:
                words.put(f'/{word}')#skips append on words that already have extension
            else:
                words.put(f'/{word}/')#pulls out words
                for extension in EXTENSIONS:#append extensions to words
                    words.put(f'/{word}{extension}')
    
        with open(WORDLIST) as f:
            raw_words = f.read() #read words from wordlist
        found_resume = False
        words = Queue()#append words to queue
        for word in raw_words.split():
            if resume is not None:
                if found_resume:
                    extend_words(word)
                elif word == resume:
                    found_resume = True
                    print(f'Resuming wordlist from: {resume}\n')
            else:
                print(word)
                extend_words(word)
        return words

    def dir_bruter(target, words):
        headers = {'User-Agent': AGENT}
        locker = threading.Lock() #implemented to allow writing from threads to file
        TARGET = target
        while not words.empty():
            url = f'{TARGET}{words.get()}'#append target links to target url
            url = url.replace('\\','/')
            try:
                r = requests.get(url, headers=headers)#collect what connection response is recieved
            except requests.exceptions.ConnectionError:#in case of a request connection error mark as invalid and clear log
                sys.stderr.write('x');sys.stderr.flush()
                continue
            if r.status_code == 200:
                print(f'\nSuccess ({r.status_code}: {url})')#print success in new line if a file path is found
                locker.acquire()
                l = BeautifulSoup(r.text,'html.parser')
                str1 = ''.join((url, ': ', str(r.status_code),'\n'))
                print(str1)
                targetFound = str(url + '\n')
                text = str(l)
                text = str(text.encode('utf-8'))
                with open('Headers.csv', 'a') as headerFile:
                    headerFile.write(text)
                    headerFile.close()
                print(text)
                #if "While the 0bit website is getting remastered" not in text:
                #    print("Real")
                with open('targetsfound.txt', 'a') as t:#append to created targetsfound.txt
                    t.write(targetFound)
                    t.close()
                #else:
                #    print("Fake")
                locker.release()
            elif r.status_code == 404:
                sys.stderr.write('.');sys.stderr.flush()#Print . if path exists but is inaccessible and flush error
            else:
                print(f'{r.status_code} => {url}')#return what code is thrown on a particular url

class sqlInjector():
    def __init__(self, url):
        self.url = url      #identify url
        print(f'\nBrute Force Attack beginning on {url}.\n')
        
        
    def get_words():#collect words from wordlist
        with open('sqlpayloads.txt') as f:
            raw_words = f.read()
        
        words = Queue()
        for word in raw_words.split():
            words.put(word)
        return words
    
    def form_details(form):#gather data from forms
        detailsOfForm = {}
        action = form.attrs.get("action")
        method = form.attrs.get("method", "get")
        inputs = []
        
        for input_tag in form.find_all("input"):
            input_type = input_tag.attrs.get("type", "text")
            input_name = input_tag.attrs.get("name", "")
            input_value = input_tag.attrs.get("value", "")
            inputs.append(
                {"type": input_type, "name": input_name, "value": input_value}
            )
            
        detailsOfForm["action"] = action
        detailsOfForm["method"] = method
        detailsOfForm["inputs"] = inputs
        return detailsOfForm
    #create threads and begin initializer
    def vulnerable(response):
        errors = {"quoted string not properly terminated",
              "unclosed quotation mark after the character string", 
              "you have an error in your sql syntax;"}
      
        for error in errors:
            if error in response.content.decode().lower():
                return True
        return False

    def get_forms(url):
        soup = BeautifulSoup(s.get(url).content, "html.parser")
        return soup.find_all("form"), soup.find_all("input")
    
    def run_bruteforce(self, payloads):
        for _ in range(10):
            t = threading.Thread(target=self.injection, args=(payloads,))
            t.start()
        
    def injection(self, payloads):
        s = requests.Session()
        try:
            while not payloads.empty():
                time.sleep(5)
                pay = payloads.get()
                i = random.choice((1,2,3))
                if(i == 1):
                    pay = ''.join(random.choice((str.upper, str.lower))(c) for c in pay)
                print(f'[+]Trying payloads {pay:<10}')
                time.sleep(2)

                for form in forms:
                    details = sqlInjector.form_details(form)
                    data = {}
                        
                    for input_tag in details["inputs"]:
                        if input_tag["type"] == "hidden" or input_tag["value"]:
                            data[input_tag["name"]] = input_tag["value{}".format(payloads.get())]
                        elif input_tag["type"] != "submit":
                            data[input_tag["name"]] = f"test{payloads.get()}"
                
                    url = urljoin(self.url, details["action"])
                    
                    if details["method"] == "post":
                        res = s.post(url, data=data)
                    elif details["method"] == "get":
                        res = s.get(url, data=data)
                    try:
                        if sqlInjector.vulnerable(res):
                            print("[+]SQL Injection attack vulnerability detected in link:", url)
                        else:
                            print("[-]No SQL Injection vulnerability detected")
                            break
                    except UnboundLocalError as e:
                        print("Error: {}".format(e))
                        sys.stderr.flush()
        except KeyboardInterrupt:
            exit()


if __name__ == '__main__':
    parser = argparse.ArgumentParser( 
    description='Widespread Tool',
    formatter_class=argparse.RawDescriptionHelpFormatter,
    epilog=textwrap.dedent('''Example: 
    -s hackthissite.org # Scan Ports
    -m https://hackthissite.org # File Mapping
    -i https://hackthissite.org # Send request on targets located
    '''))
    parser.add_argument('-s', '--scanner', help='#Scan ports on network') 
    parser.add_argument('-m', '--mapper', help='#Execute network file map')
    parser.add_argument('-i', '--inject', help='#Send request and gather form data')
    args = parser.parse_args()
    if args.mapper:
        TARGET = args.mapper
        if 'https://' in TARGET: 
            pass
        else:
            TARGET = 'https://' + TARGET

        words = dataGatherer.get_words()#collect words from wordlist
        print('Press return to continue.')
        sys.stdin.readline()
        try:
            for _ in range(THREADS):#spin up all threads
                t = threading.Thread(target=dataGatherer.dir_bruter, args=(TARGET, words, ))#utilize threats to use bruter directory to target links through all.txt
                t.start()
        except error:
            pass
    elif args.scanner:
        TARGET = args.scanner
        PortScanner.main(TARGET)
    elif args.inject:
        url = args.inject
        b = sqlInjector(url)#Target user password
        words= b.get_words()#collect word
        forms, inputs = b.get_forms(url)
        print(f"[+] Detected {len(forms)} forms and {len(inputs)} inputs on {url}.")
        try:
            b.run_bruteforce(words)
        except KeyboardInterrupt():
            exit()
    else:
        prompt = input("Spawn prompt?(y/n): ")
        if prompt.lower() == 'y':
            os.system("start cmd /k title Hacker's CMD^&color 02")
        else:
            pass